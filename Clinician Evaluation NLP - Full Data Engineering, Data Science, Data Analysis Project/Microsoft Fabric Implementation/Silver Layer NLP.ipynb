{"cells":[{"cell_type":"markdown","source":["# Silver Layer -  NLP, GPT Processing of Raw Data"],"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"0d3dc75b-105e-4a4d-bc82-4136124a6123"},{"cell_type":"code","source":["from datetime import datetime\n","import re\n","\n","import nltk\n","import nltk.data\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","from nltk.corpus import stopwords\n","from nltk.chunk import RegexpParser\n","\n","from pyspark.sql.functions import col, expr, to_date\n","from pyspark.sql.functions import regexp_extract\n","\n","import ast\n","\n","import openai\n","from openai import OpenAI\n","\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n","\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","df = spark.sql(\"SELECT * FROM PT_evals_lakehouse.bronze_layer_nlp LIMIT 1000\")\n","\n","# Only act upon those rows which are new for the week\n","df = df.withColumn('eval_date', to_date(col('eval_date'), 'yyyy-MM-dd'))\n","df = df.filter(expr(f\"eval_date >= TO_DATE('{last_added_date}', 'yyyy-MM-dd')\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.1623752Z","session_start_time":"2024-08-09T15:27:22.3746598Z","execution_start_time":"2024-08-09T15:28:14.1405058Z","execution_finish_time":"2024-08-09T15:28:32.5312661Z","parent_msg_id":"3ac26479-32c4-406f-9315-193f8a5e5041"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /home/trusted-service-\n[nltk_data]     user/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/trusted-service-user/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}],"execution_count":1,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":true,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7f050ad5-9260-4a37-903d-7400ab262b98"},{"cell_type":"code","source":["# Regular expressions to clean and collect age, sex, fusion, brace, pain data\n","\n","age_pattern = '\\d+'\n","sex_pattern = '\\S*male'\n","fusion_pattern = '(cervical|lumbar)'\n","brace_pattern = '\\D*lso|aspen'\n","pain_pattern = '\\d+'\n","\n","df = (df\n","      .withColumn('age', regexp_extract('age_sex', age_pattern, 0))\n","      .withColumn('sex', regexp_extract('age_sex', sex_pattern, 0))\n","      .withColumn('fusion', regexp_extract('fusion', fusion_pattern, 0))\n","      .withColumn('brace', regexp_extract('brace', brace_pattern, 0))\n","      .withColumn('pain', regexp_extract('pain', pain_pattern, 0))\n",")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.1693543Z","session_start_time":null,"execution_start_time":"2024-08-09T15:28:33.0433654Z","execution_finish_time":"2024-08-09T15:28:33.2961049Z","parent_msg_id":"959b31e5-dc4a-43f0-9f1e-c2161503bea0"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"73157b94-907b-4ddc-9937-1ea26b17a5a5"},{"cell_type":"code","source":["# Function to determine names and extract only the last name\n","def extract_last_name(name):\n","    if not name:\n","        return None\n","\n","    tagged_tokens = pos_tag(word_tokenize(name))\n","    grammar = \"NAME: {<NNP>+}\"\n","    chunk_parser = RegexpParser(grammar)\n","    chunked = chunk_parser.parse(tagged_tokens)\n","\n","    titles = {'Md', 'Np', 'Do', 'Pa'}\n","    last_name = None\n","\n","    for subtree in chunked:\n","        if isinstance(subtree, nltk.Tree) and subtree.label() == 'NAME':\n","            name_tokens = [token for token, pos in subtree.leaves() if token not in titles]\n","            if name_tokens:\n","                last_name = name_tokens[-1]\n","\n","    return last_name\n","\n","# Necessary function for pos_tags to identify names\n","def to_title(text):\n","    return text.title()\n","\n","# Register both expressions for use\n","spark.udf.register(\"to_title\", to_title)\n","spark.udf.register('extract_last_name', extract_last_name)\n","\n","df = (df.withColumn('ordering_provider', expr('to_title(ordering_provider)')).withColumn('ordering_provider', expr('extract_last_name(ordering_provider)')))\n","df.persist()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.1913933Z","session_start_time":null,"execution_start_time":"2024-08-09T15:28:33.9493623Z","execution_finish_time":"2024-08-09T15:28:39.2498175Z","parent_msg_id":"b880a9de-801a-4b54-b937-dd1509864074"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"DataFrame[eval_date: date, age_sex: string, fusion: string, ordering_provider: string, brace: string, pain: string, plof: string, mobility: string, age: string, sex: string]"},"metadata":{}}],"execution_count":3,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"9d3452d6-2bf7-461d-8346-e618cec69182"},{"cell_type":"code","source":["client = OpenAI(api_key = 'sk-proj-vCT4yV5uyXXTjEQQMmSZT3BlbkFJg9gjbWTRzgrswM1mTsOL')\n","\n","# List for OpenAI to iterate through\n","plof = df.select(\"plof\").rdd.flatMap(lambda x: x).collect()\n","\n","# Lists to dump data\n","prior_loc = []\n","ste = []\n","hr = []\n","ad = []\n","num_falls = []\n","\n","list_pattern = '(\\[.*\\])'\n","\n","for eval_plof in plof:\n","    plof_prompt = f\"\"\"\n","    You are an automated data extractor. Your only goal is to analyze the following paragraph for the data listed and return it in the format\n","    required below. The paragraph describes the living situation and prior level of function of \n","    a patient who is admitted in the hospital.\n","    \n","    Extract the following information and return it in the format listed below the paragraph.\n","    1. Type of location that the patient was living in. If they plan to live in another location, such as an individual who lives in a two story home\n","    but plans to stay in a ranch home, then encode the ranch home. We will encode this as follows:\n","        Ranch home or single story home (ssh): 0\n","        Two or more story home (2sh): 1\n","        Apartment: 2\n","        Independent living facility (ILF): 3\n","        Assisted living facility (ALF): 4\n","        Skilled nursing facility (SNF): 5\n","        Inpatient rehabilitation hospital: 6\n","        Long-term care facility (LTC): 7\n","    2. Number of stairs (steps). If the paragraph mentions \"1+1 ste\" or \"1+1 stairs to enter\", reduce this to 1. Otherwise, \n","    perform the necessary addition.\n","    3. Number of handrails present. If the paragraph makes no mention of handrails, sometimes abbreviated as \"hr\" or \"hrs\", then this is 0.\n","    4. Type of assistive device used. If this is not mentioned, then assume no assistive device. We will encode the assistive device used, if any:\n","        No assistive device used: 0\n","        Cane: 1\n","        Walker: 2\n","    5. Number of falls in the last six months.\n","    \n","    \n","    Paragraph:\n","    \\\"\\\"\\\"\n","    {eval_plof}\n","    \\\"\\\"\\\"\n","    \n","    Response format will be in the form of a python list with only the integers returned. For example: \"[ 1, 3, 2, 0, 3]\" where:\n","        Number of stories in the house is at index 1.\n","        Number stairs (steps) is at index 2.\n","        Number of handrails is at index 3.\n","        Assistive device used is at index 4.\n","        Number of falls in the last 6 months is at index 5.\n","\n","    Do not return an explanation. Only return the python list.\n","    \"\"\"\n","    \n","    response = client.chat.completions.create(\n","        model = \"gpt-4o\",\n","        messages = [\n","            {\"role\":\"user\",\"content\":plof_prompt}\n","        ]\n","    )\n","    # Gather responses\n","    gpt_plof_response = response.choices[0].message.content\n","\n","    # Collect and convert responses into a list of lists\n","    plof_list = ast.literal_eval(re.search(list_pattern,gpt_plof_response).group())\n","\n","    # Dump data into respective lists\n","    prior_loc.append(plof_list[0])\n","    ste.append(plof_list[1])\n","    hr.append(plof_list[2])\n","    ad.append(plof_list[3])\n","    num_falls.append(plof_list[4])\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.192186Z","session_start_time":null,"execution_start_time":"2024-08-09T15:28:39.9761639Z","execution_finish_time":"2024-08-09T15:28:52.5107988Z","parent_msg_id":"db750a0c-b2e5-4f3c-8dcf-e9e41e853037"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":false,"source_hidden":true},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"62b9b5fb-9e15-4545-b8f3-b72f5af1fb21"},{"cell_type":"code","source":["list_pattern = '(\\[.*\\])'\n","\n","# List for OpenAI to iterate through\n","mobility = df.select(\"mobility\").rdd.flatMap(lambda x: x).collect()\n","\n","# Lists to dump datas\n","sup_sit = []\n","sit_stand = []\n","amb_assist = []\n","amb_distance = []\n","stairs_assist = []\n","num_stairs = []\n","\n","for eval_mob in mobility:\n","    mobility_prompt = f\"\"\"\n","    \n","    You are an automated data extractor. Your only goal is to analyze the following paragraph for the data listed and return it in the format\n","    required below. The paragraph describes the mobility assessment performed on a patient following a surgical fusion \n","    that is in an inpatient hospital. \n","    \n","    The purpose of this analysis is to retrieve information regarding the assistance required to perform various mobility, \n","    distance of ambulation, and number of stairs completed during the session. Some portions of information may not be available as they \n","    might not have been performed.\n","    \n","    Assistance ranges from:\n","    SBA: Stand-by-assistance\n","    Min-A: Minimal assistance\n","    Mod-A: Moderate assistance\n","    Max-A: Maximal Assistance\n","    'x#' where # is the number of individuals assisting. For example, minAx1 means minimal assistance of 1.\n","    \n","    Distance is measured in feet.\n","    \n","    Extract the following information and return it in the format listed below the paragraph. \n","    1. Supine to sit (also written as sup < > sit or sup to sit) assistance required\n","    2. Sit to stand (also written as sit < > stand) assistance required\n","    3. Ambulation assistance required\n","    4. Ambulation distance (If Ambulation assistance required is 4, then this value is 0.)\n","    5. Stairs assistance required\n","    6. Stairs completed (If stairs assistance is 4, then this value is 0.)\n","    \n","    Paragraph:\n","    \\\"\\\"\\\"\n","    {eval_mob}\n","    \\\"\\\"\\\"\n","    \n","    Return the assistance variables in the encoded format:\n","    Stand-by-assistance: 0\n","    Minimal assistance of 1: 1\n","    Moderate assistance of 1: 2\n","    Maximal assistance of 1 or more, moderate assistance of 2: 3\n","    Unable to complete, did not complete, or not feasible to complete: 4\n","    \n","    Response format will only be in the form of a python list with only the integers returned. For example: \"[ 1, 3, 2, 100, 3, 6]\"\n","    where:\n","        Supine to sit assistance is index 0.\n","        Sit to stand assistance is index 1.\n","        Ambulation assistance is index 2.\n","        Ambulation distance is index 3.\n","        Stairs assistance is index 4.\n","        Stairs completed is index 5.\n","\n","    Do not return an explanation. Only return the python list.\n","    \"\"\"\n","    \n","    response = client.chat.completions.create(\n","        model = \"gpt-4o\",\n","        messages = [\n","            {\"role\":\"user\",\"content\":mobility_prompt}\n","        ]\n","    )\n","\n","    # Gather responses\n","    gpt_mob_response = response.choices[0].message.content\n","\n","    # Collect and convert responses into a list of lists\n","    mobility_list = ast.literal_eval(re.search(list_pattern,gpt_mob_response).group())\n","    \n","    # Dump data into respective lists\n","    sup_sit.append(mobility_list[0])\n","    sit_stand.append(mobility_list[1])\n","    amb_assist.append(mobility_list[2])\n","    amb_distance.append(mobility_list[3])\n","    stairs_assist.append(mobility_list[4])\n","    num_stairs.append(mobility_list[5])\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.1928633Z","session_start_time":null,"execution_start_time":"2024-08-09T15:28:53.2110161Z","execution_finish_time":"2024-08-09T15:29:01.4265616Z","parent_msg_id":"37524da7-73d2-4fca-9c76-68cb6cd1228d"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"da33769d-bc61-46e7-bc6f-521752b26b37"},{"cell_type":"code","source":["from pyspark.sql import Window\n","from pyspark.sql.functions import row_number\n","\n","# New DataFrame columns to join to original\n","data = list(zip(prior_loc, ste, hr, ad, num_falls, sup_sit, sit_stand, amb_assist, amb_distance, stairs_assist, num_stairs))\n","columns = ['prior_loc', 'ste', 'hr', 'ad', 'num_falls', 'sup_sit', 'sit_stand', 'amb_assist', 'amb_distance', 'stairs_assist', 'num_stairs']\n","new_df = spark.createDataFrame(data, columns)\n","\n","# Indexes to join DataFrames upon\n","window = Window.orderBy(\"ordering_provider\")  \n","df = df.withColumn(\"index\", row_number().over(window))\n","new_df = new_df.withColumn(\"index\", row_number().over(Window.orderBy(\"prior_loc\")))\n","\n","# Join DataFrames\n","df = df.join(new_df, on=\"index\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.1935053Z","session_start_time":null,"execution_start_time":"2024-08-09T15:29:02.1084624Z","execution_finish_time":"2024-08-09T15:29:02.3905901Z","parent_msg_id":"e540a580-ae24-480b-8090-021c3aee4c86"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"e32b3f6c-8196-4afc-b393-3f27b40244f5"},{"cell_type":"code","source":["df = df.drop('age_sex').drop('mobility').drop('plof').drop(\"index\")\n","\n","df = df.withColumn(\"eval_date\", col(\"eval_date\").cast(DateType())) \\\n","       .withColumn(\"fusion\", col(\"fusion\").cast(StringType())) \\\n","       .withColumn(\"ordering_provider\", col(\"ordering_provider\").cast(StringType())) \\\n","       .withColumn(\"brace\", col(\"brace\").cast(StringType())) \\\n","       .withColumn(\"pain\", col(\"pain\").cast(IntegerType())) \\\n","       .withColumn(\"age\", col(\"age\").cast(IntegerType())) \\\n","       .withColumn(\"sex\", col(\"sex\").cast(StringType())) \\\n","       .withColumn(\"prior_loc\", col(\"prior_loc\").cast(IntegerType())) \\\n","       .withColumn(\"ste\", col(\"ste\").cast(IntegerType())) \\\n","       .withColumn(\"hr\", col(\"hr\").cast(IntegerType())) \\\n","       .withColumn(\"ad\", col(\"ad\").cast(IntegerType())) \\\n","       .withColumn(\"num_falls\", col(\"num_falls\").cast(IntegerType())) \\\n","       .withColumn(\"sup_sit\", col(\"sup_sit\").cast(IntegerType())) \\\n","       .withColumn(\"sit_stand\", col(\"sit_stand\").cast(IntegerType())) \\\n","       .withColumn(\"amb_assist\", col(\"amb_assist\").cast(IntegerType())) \\\n","       .withColumn(\"amb_distance\", col(\"amb_distance\").cast(IntegerType())) \\\n","       .withColumn(\"stairs_assist\", col(\"stairs_assist\").cast(IntegerType())) \\\n","       .withColumn(\"num_stairs\", col(\"num_stairs\").cast(IntegerType()))\n","\n","# Configure schema\n","new_schema = StructType([\n","    StructField(\"eval_date\", DateType(), True),\n","    StructField(\"fusion\", StringType(), True),\n","    StructField(\"ordering_provider\", StringType(), True),\n","    StructField(\"brace\", StringType(), True),\n","    StructField(\"pain\", IntegerType(), True),\n","    StructField(\"age\", IntegerType(), True),\n","    StructField(\"sex\", StringType(), True),\n","    StructField(\"prior_loc\", IntegerType(), True),\n","    StructField(\"ste\", IntegerType(), True),\n","    StructField(\"hr\", IntegerType(), True),\n","    StructField(\"ad\", IntegerType(), True),\n","    StructField(\"num_falls\", IntegerType(), True),\n","    StructField(\"sup_sit\", IntegerType(), True),\n","    StructField(\"sit_stand\", IntegerType(), True),\n","    StructField(\"amb_assist\", IntegerType(), True),\n","    StructField(\"amb_distance\", IntegerType(), True),\n","    StructField(\"stairs_assist\", IntegerType(), True),\n","    StructField(\"num_stairs\", IntegerType(), True)\n","])\n","\n","df = spark.createDataFrame(df.rdd, schema = new_schema)\n","\n","df.write.mode('append').saveAsTable('silver_layer_nlp')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"76dab440-8afc-4d2e-94a2-168afc801ed6","normalized_state":"finished","queued_time":"2024-08-09T15:27:21.1941561Z","session_start_time":null,"execution_start_time":"2024-08-09T15:29:03.0309757Z","execution_finish_time":"2024-08-09T15:29:09.4491718Z","parent_msg_id":"83e24b25-fc7d-498e-b725-f8facce82c90"},"text/plain":"StatementMeta(, 76dab440-8afc-4d2e-94a2-168afc801ed6, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"id":"7e933c1e-6329-41d5-aaa4-afa1de554ec9"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"environment":{"environmentId":"bca2ff44-1629-4724-860f-6a970a7e3659","workspaceId":"8ee4903a-6e90-4510-b3c2-424d07933817"},"lakehouse":{"default_lakehouse":"e88fef1f-d55a-4f2c-bad7-9ecc1cafd638","default_lakehouse_name":"PT_evals_lakehouse","default_lakehouse_workspace_id":"8ee4903a-6e90-4510-b3c2-424d07933817"}}},"nbformat":4,"nbformat_minor":5}