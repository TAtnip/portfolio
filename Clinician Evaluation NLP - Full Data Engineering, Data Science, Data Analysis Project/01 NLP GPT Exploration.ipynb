{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0825c4-53ab-498d-b8fb-426649e2c5cf",
   "metadata": {},
   "source": [
    "## Part 1: Data Extraction\n",
    "\n",
    "In this section, I will extract raw data from the physical therapist evaluation and perform data cleaning for later use in Data Analytics and the building of several machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738d5393-62a8-4938-bf12-4f7e9dd9a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.chunk import RegexpParser\n",
    "import spacy\n",
    "\n",
    "\n",
    "## Feature information\n",
    "age_sex = []\n",
    "fusion = []\n",
    "ordering_provider = []\n",
    "brace = []\n",
    "pain = []\n",
    "plof = []\n",
    "prior_loc = []\n",
    "ste = []\n",
    "hr = []\n",
    "ad = []\n",
    "num_falls = []\n",
    "mobility = []\n",
    "sup_sit = []\n",
    "sit_stand = []\n",
    "amb_distance = []\n",
    "amb_assist = []\n",
    "stairs_assist = []\n",
    "num_stairs = []\n",
    "\n",
    "# Initial label Information\n",
    "los = []\n",
    "dc_loc = []\n",
    "\n",
    "# 10 .txt files of Evaluations are located in the folder 'Initial_Evaluations'\n",
    "data_folder = os.path.join(os.getcwd(),'Initial_Evaluations')\n",
    "\n",
    "for root, folder, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        path = os.path.join(root, file)\n",
    "\n",
    "        ## Avoid analysis of checkpoint folders\n",
    "        if '.ipynb_checkpoints' in path:\n",
    "            continue\n",
    "\n",
    "        with open(path) as curr_file:\n",
    "            lines = curr_file.readlines()\n",
    "            \n",
    "        collect_plof = False\n",
    "        collect_mobility = False\n",
    "        curr_mobility = []\n",
    "        curr_plof = []\n",
    "        ## Initial data collection from evaluations\n",
    "        for line in lines:\n",
    "            line = line.lower()\n",
    "        \n",
    "            if line.startswith('reason for admission:'):\n",
    "                fusion.append(line.split('reason for admission:')[1].strip())\n",
    "            if line.startswith('ordered by:'):\n",
    "                ordering_provider.append(line.split('ordered by:')[1].strip())\n",
    "            if line.startswith('precautions:'):\n",
    "                brace.append(line.split('precautions:')[1].strip())\n",
    "            if line.startswith('subjective:'):\n",
    "                pain.append(line.split('subjective:')[1].strip())\n",
    "            if line.startswith('living situation/prior level of function:'):\n",
    "                collect_plof = True\n",
    "                curr_plof.append(line.split('living situation/prior level of function:')[1].strip())\n",
    "                continue\n",
    "            if line.startswith(\"objective:\"):\n",
    "                collect_plof = False\n",
    "            if collect_plof:\n",
    "                curr_plof.append(line)\n",
    "            if line.startswith('appearance:'):\n",
    "                age_sex.append(line.split('appearance:')[1].strip())\n",
    "            if line.startswith('mobility assessment:'):\n",
    "                collect_mobility = True\n",
    "                continue\n",
    "            if line.startswith(\"assessment:\"):\n",
    "                collect_mobility = False\n",
    "            if collect_mobility:\n",
    "                curr_mobility.append(line)\n",
    "        mobility.append(''.join(curr_mobility))\n",
    "        plof.append(''.join(curr_plof))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246aa1d0-0df8-4b15-8f77-5d94e6f3773e",
   "metadata": {},
   "source": [
    "Let's confirm we extracted information from 10 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffeb9339-54b2-4f52-89ac-6c1f9189c05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of brace list: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of brace list: {len(brace)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0c796-a0c9-416e-b657-463bac27da6c",
   "metadata": {},
   "source": [
    "Note: I am not able to collect labels as these are not real evaluations. In a live setting, the labels, length of stay and discharge location, would be collected from the electronic medical record, specifically from the discharge summary. I will create a function to 'guess' this data in the **Evaluation Generator** section of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd8e9e-40b7-4e89-ad03-4d7b87ed05d8",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleansing and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079596c6-2257-4f71-82b0-b6c21f1995f6",
   "metadata": {},
   "source": [
    "I will now clean age_sex, fusion, ordering_provider, brace, and pain using *re*, regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3136d281-5a05-48d3-aa12-841d8ea3a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ages: ['68', '71', '70', '75', '70', '82', '65', '72', '78', '75']\n",
      " Sex: ['female', 'male', 'female', 'male', 'female', 'female', 'male', 'male', 'male', 'male']\n",
      " Fusion Types: ['lumbar', 'lumbar', 'lumbar', 'cervical', 'cervical', 'cervical', 'cervical', 'cervical', 'lumbar', 'lumbar']\n",
      " Brace required: ['lso', 'tlso', 'lso', 'aspen', 'aspen', 'aspen', 'aspen', 'aspen', 'lso', 'tlso']\n",
      " Pain level: ['7', '5', '3', '8', '2', '5', '4', '10', '9', '9']\n"
     ]
    }
   ],
   "source": [
    "age_pattern = '\\d+'\n",
    "sex_pattern = '\\S*male'\n",
    "fusion_pattern = '(cervical|lumbar)'\n",
    "brace_pattern = '\\D*lso|aspen'\n",
    "pain_pattern = '\\d+'\n",
    "\n",
    "def extract_pattern(pattern,raw_list):\n",
    "    clean_list = [re.search(pattern,patient).group() for patient in raw_list]\n",
    "    return clean_list\n",
    "\n",
    "age = extract_pattern(age_pattern, age_sex)\n",
    "sex = extract_pattern(sex_pattern, age_sex)\n",
    "fusion = extract_pattern(fusion_pattern,fusion)\n",
    "brace = extract_pattern(brace_pattern,brace)\n",
    "pain = extract_pattern(pain_pattern,pain)\n",
    "\n",
    "print(f' Ages: {age}')\n",
    "print(f' Sex: {sex}')\n",
    "print(f' Fusion Types: {fusion}')\n",
    "print(f' Brace required: {brace}')\n",
    "print(f' Pain level: {pain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6ea1f-d5df-4c68-a84f-e295b0c667a5",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "I will use Named Entity Recognition to retrieve the last names of the ordering providers. I believe this will be easier to maintain over time than searching for specific providers in a list that would require updating. \n",
    "\n",
    "\\* *I sorted out titles as some would be flagged incorrectly as proper nouns, such as Np.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd759880-d041-4b96-b023-f9f044a68f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Provider last names: ['Nolan', 'Myers', 'Myers', 'Myers', 'Kuzak', 'Kuzak', 'Myers', 'Myers', 'Nolan', 'Nolan']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_tag(names):\n",
    "    tagged_tokens = [pos_tag(word_tokenize(name)) for name in names]\n",
    "    return tagged_tokens\n",
    "\n",
    "def extract_last_name(names):\n",
    "    tagged_tokens_list = tokenize_tag(names)\n",
    "\n",
    "    # Search and parse for proper nouns\n",
    "    grammar = \"NAME: {<NNP>+}\"\n",
    "    chunk_parser = RegexpParser(grammar)\n",
    "    last_name = []\n",
    "    for tagged_tokens in tagged_tokens_list:\n",
    "        chunked = chunk_parser.parse(tagged_tokens)\n",
    "\n",
    "        # Titles to avoid categorizing as proper nouns \n",
    "        titles = {'Md', 'Np', 'Do', 'Pa'}\n",
    "\n",
    "        \n",
    "        for subtree in chunked:\n",
    "            if isinstance(subtree, nltk.Tree) and subtree.label() == 'NAME':\n",
    "                # Filter out titles and get the last proper noun\n",
    "                name_tokens = [token for token, pos in subtree.leaves() if token not in titles]\n",
    "                if name_tokens:\n",
    "                    last_name.append(name_tokens[-1]) # Retrieve only the last name\n",
    "        \n",
    "    return last_name\n",
    "\n",
    "name_string = ['Bob Kuzak, Md, Np','Billy Smith, Md']\n",
    "ordering_provider = [provider.title() for provider in ordering_provider]\n",
    "provider = extract_last_name(ordering_provider)\n",
    "\n",
    "print(f' Provider last names: {provider}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975be988-ce5e-48ed-b1d1-a8f1de7b31e5",
   "metadata": {},
   "source": [
    "## Conversion of unstructured text into structured data: an Exploration of Gensim\n",
    "\n",
    "There is significant variation in how prior living situation and level of function may be documented by therapists. Most choose to document in unstructured paragraphs. The information typically contains:\n",
    "\n",
    "**Living location**, including whether the home is a single story, or multi-story home and thus requiring stairs to reach the patient's bedroom/bathroom\n",
    "\n",
    "**Stairs to enter the home (ste) and corresponding number of handrails**\n",
    "\n",
    "**Falls in the last 6 months**, a significant risk factor for future falls\n",
    "\n",
    "**Prior use of an assistive device**\n",
    "\n",
    "My previous use of *re* alone will be difficult to accurately capture these pieces of information due to the variation in therapist sentence structure and word choice. Thus, I will attempt to handle this with Gensim. Gensim is a open-source library created by Google which attempts to utilize vector modeling to handle natural-language-processing tasks. I will be using Word2Vec with the previously trained Google News 300 model which contains 300 billion running words and 3 million 300 dimension english word vectors.\n",
    "\n",
    "By taking advantage of this pre-trained model, I am able to calculate a numerical difference between texts. This is termed the 'Word Mover's Distance'. In the next cell I will calculate the difference between a living scenario of a single story house compared to various other living scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a5f0ed-5891-4b26-97d5-7cc0af702134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between \"I live single story house\" and \"I live two story house\": 0.2388\n",
      "Distance between \"I live single story house\" and \"I live skilled nursing facility\": 0.3446\n",
      "Distance between \"I live single story house\" and \"I live assisted living facility\": 0.3535\n",
      "Distance between \"I live single story house\" and \"I live independent living facility\": 0.4262\n",
      "Distance between \"I live single story house\" and \"I live apartment\": 0.4733\n",
      "Distance between \"I live single story house\" and \"I live single story house\": 0.0000\n"
     ]
    }
   ],
   "source": [
    "import gensim ## requires sciPy 1.10.1 due to triu, tru, and tril being deprecated\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim import models\n",
    "import gensim.downloader as api\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "\n",
    "# Strings of different living scenarios\n",
    "ssh = 'I live in a single story house'\n",
    "two_sh = 'I live in a two story house'\n",
    "nf = 'I live in a skilled nursing facility'\n",
    "alf = 'I live in an assisted living facility'\n",
    "ilf = 'I live in an independent living facility'\n",
    "apt = 'I live in a apartment'\n",
    "\n",
    "prior_location = [two_sh, nf, alf, ilf, apt]\n",
    "\n",
    "# Removal of stop words and use of lemmatization have been shown to improve results when using Word Mover's Distance\n",
    "processed_ssh = ' '.join([word.lemma_ for word in nlp(ssh) if not word.text in stop_words])\n",
    "\n",
    "for loc in prior_location:\n",
    "    processed_loc = ' '.join([word.lemma_ for word in nlp(loc) if not word.text in stop_words])\n",
    "    wmd = model.wmdistance(processed_ssh, processed_loc)\n",
    "    print(f'Distance between \"{processed_ssh}\" and \"{processed_loc}\": {wmd:.4f}')\n",
    "\n",
    "# The difference between two of the same sentences is 0.000\n",
    "wmd_ssh = model.wmdistance(processed_ssh, processed_ssh)\n",
    "print(f'Distance between \"{processed_ssh}\" and \"{processed_ssh}\": {wmd_ssh:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698afd01-c83a-45ad-9e12-0cccbb9e7b6c",
   "metadata": {},
   "source": [
    "We would expect that two strings that mention houses would be more similar than a string that mentions living in a house and another that mentions living in a type of facility. As seen in the text above, strings that are more similar have a lower word mover's distance than those that are more different. This seems promising. \n",
    "\n",
    "The following cell will show if word mover's distance can handle sentence structure and word choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee02de2-7339-4f23-ba8a-25487a4be061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between I do not live in a two story house, I live in a single story house and I do not live in a single story house, I live in a two story house: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# The equivalent of I live in a two story house\n",
    "sentence_two_sh = 'I do not live in a single story house, I live in a two story house'\n",
    "\n",
    "process_two_sh = ' '.join([word.lemma_ for word in nlp(sentence_two_sh) if not word.text in stop_words])\n",
    "\n",
    "# The equivalent of I live in a single story house\n",
    "sentence_ssh = 'I do not live in a two story house, I live in a single story house'\n",
    "\n",
    "process_ssh = ' '.join([word.lemma_ for word in nlp(sentence_ssh) if not word.text in stop_words])\n",
    "\n",
    "# Calculate WMD\n",
    "wmd_sentences = model.wmdistance(process_two_sh, process_ssh)\n",
    "print(f'Distance between {sentence_ssh} and {sentence_two_sh}: {wmd_sentences:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a62245-82b6-4291-9d65-123b7051514c",
   "metadata": {},
   "source": [
    "These sentences depict different living situations, however they return a word mover's distance of 0.000. This may lead to inaccuracies over time.\n",
    "\n",
    "I will now experiment on what might occur when the model is given a paragraph with information rather than a sentence. I will include typical living situations a therapist might document. In this example, in an attempt to challenge word mover's distance further, the second paragraph will describe a patient who typically lives in a single story home but plans to move in with their son in a two story home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b0878e-76c5-41bc-8d36-bafa5fdb527a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1:\n",
      "\n",
      "Distance between paragraph 1 and \"patient live single story house\": 0.2148\n",
      "Distance between paragraph 1 and \"patient live two story house\": 0.2907\n",
      "Distance between paragraph 1 and \"patient live skilled nursing facility\": 0.3265\n",
      "Distance between paragraph 1 and \"patient live assisted living facility\": 0.3791\n",
      "Distance between paragraph 1 and \"patient live independent living facility\": 0.3881\n",
      "Distance between paragraph 1 and \"patient live apartment\": 0.4109\n",
      "\n",
      "\n",
      "Paragraph 2:\n",
      "\n",
      "Distance between paragraph 2 and \"patient live single story house\": 0.2634\n",
      "Distance between paragraph 2 and \"patient live two story house\": 0.2828\n",
      "Distance between paragraph 2 and \"patient live skilled nursing facility\": 0.3664\n",
      "Distance between paragraph 2 and \"patient live assisted living facility\": 0.4055\n",
      "Distance between paragraph 2 and \"patient live independent living facility\": 0.4463\n",
      "Distance between paragraph 2 and \"patient live apartment\": 0.4939\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssh = 'Patient lives in a single story house'\n",
    "two_sh = 'Patient lives in a two story house'\n",
    "nf = 'Patient lives in a skilled nursing facility'\n",
    "alf = 'Patient lives in an assisted living facility'\n",
    "ilf = 'Patient lives in an independent living facility'\n",
    "apt = 'Patient lives in a apartment'\n",
    "\n",
    "prior_location = [ssh, two_sh, nf, alf, ilf, apt]\n",
    "\n",
    "# Paragraph 1 describes a patient who lives in a single story house\n",
    "ssh_paragraph = (f'Patient lives in a single story house with his wife. He was previously independent with all ADLs without the use of '\n",
    "                 f'an assistive device. He has 2+2 STE with one handrail to enter the home. Denies falls in the last 6 months.')\n",
    "\n",
    "# Paragraph 2 describes a patient who lives in a single story house but plans to discharge to a two story house\n",
    "two_sh_paragraph = (f'Patient lives in a single story house with her daughter. However, she plans to move in with her son in a two story home. '\n",
    "                    f'The staircase to the second floor has 2 handrails. '\n",
    "                    f'She was previously modified independent with ADLs with the use of a walker. She has 1+1 STE. 3x falls in the '\n",
    "                    f'last 6 months.')\n",
    "\n",
    "\n",
    "my_paragraphs = [ssh_paragraph, two_sh_paragraph]\n",
    "\n",
    "def process_paragraph(paragraph):\n",
    "    processed_paragraph = ' '.join([word.lemma_ for word in nlp(paragraph) if not word.text in stop_words])\n",
    "    return processed_paragraph\n",
    "    \n",
    "for index, paragraph in enumerate(my_paragraphs):\n",
    "    print(f'Paragraph {index+1}:\\n')\n",
    "    for loc in prior_location:\n",
    "        processed_paragraph = process_paragraph(paragraph)\n",
    "        processed_loc = ' '.join([word.lemma_ for word in nlp(loc) if not word.text in stop_words])\n",
    "        wmd = model.wmdistance(processed_paragraph, processed_loc)\n",
    "        print(f'Distance between paragraph {index+1} and \"{processed_loc}\": {wmd:.4f}')\n",
    "    print(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c155476-28a8-4dd6-8d14-e6284cf38127",
   "metadata": {},
   "source": [
    "Word mover's distance alone was not able to decipher that the patient in the second paragraph has a discharge location of a two story house. There is a greater WMD between the second paragraph and the string referenced by ssh than between the string referenced by two_sh.\n",
    "\n",
    "Given the unpredictability of the unstructured data being input by therapists currently, it may end up being more efficient and thus more economical to utilize a stronger natural language processing tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f0fda-b5e2-44ee-973f-9c67a93c4a74",
   "metadata": {},
   "source": [
    "## An exploration of OpenAI API to use a GPT to retrieve the correct data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73e4fa-0b1f-4f3d-b4f4-bce96860e5b4",
   "metadata": {},
   "source": [
    "Unfortunately, word mover's distance will likely be too unreliable and produce varied results when confronted with complex paragraphs. We will now attempt to utilize the OpenAI API to use the gpt-4o model. While this does require a payment, I have found that evaluations are analyzed at much less than one cent per evaluation and it is able to handle much more complexity within paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2fedf15-5960-4a5d-a0cd-1d068585441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c8fa30-6e02-40b7-8e39-a18b8f1ac94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Number of stories in the house: 2\n",
      "2. Number of stairs (steps): 2 with 2 handrails\n",
      "3. Number of falls in the last six months: 3\n",
      "4. Assistive device used: Walker\n"
     ]
    }
   ],
   "source": [
    "# We will supply a prompt for OpenAI:\n",
    "prompt = f\"\"\"\n",
    "Analyze the following paragraph. The paragraph describes the living situation and prior level of function of \n",
    "a patient who is admitted in the hospital.\n",
    "\n",
    "Extract the following information and return it in the format listed below the paragraph.\n",
    "1. Number of stories in the living arrangement that the patient was previously at, or the patient is planning to return.\n",
    "If this is a apartment, independent living facility (ILF), skilled nursing facility (SNF), nursing home (NH), \n",
    "or assisted living facility (ALF) then the number of stories is 1. \n",
    "2. Number of stairs (steps) and the presence of a handrail.\n",
    "3. Number of falls in the last six months.\n",
    "4. Assistive device used to ambulate, if any. If the patient did not use one often, then this should be 'None'.\n",
    "Paragraph:\n",
    "\\\"\\\"\\\"\n",
    "{two_sh_paragraph}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Example response format:\n",
    "1. Number of stories in the house: 2\n",
    "2. Number of stairs (steps): 10 (5+2+3) with 1 handrail\n",
    "3. Number of falls in the last six months: 1\n",
    "4. Assistive device used: Walker\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9392bb2-6a33-4089-ad52-a9d82fe86a21",
   "metadata": {},
   "source": [
    "It appears gpt-4o was able to decipher the correct number of stories which will need to be navigated in the house. We do have some fine tuning to perform, however. The model \"hallucinated\" that there were no handrails at all on the staircase. Also, for our purposes, \"1+1 ste\" is fundamentally different than 2 stairs to enter due to the ability for a patient to utilize a walker on one step. We will modify our prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2bc93c0-e957-4f0b-936a-7a14e7466f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Number of stories in the house: 2\n",
      "2. Number stairs (steps): 1 with 2 handrails\n",
      "3. Number of falls in last 6 months: 3\n",
      "4. Assistive device used, if any: Walker\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Analyze the following paragraph. The paragraph describes the living situation and prior level of function of \n",
    "a patient who is admitted in the hospital.\n",
    "\n",
    "Extract the following information and return it in the format listed below the paragraph.\n",
    "1. Number of stories in the living arrangement that the patient was previously at, or the patient is planning to return.\n",
    "If this is a apartment, independent living facility (ILF), skilled nursing facility (SNF), nursing home (NH), long-term care facility (LTC),\n",
    "or assisted living facility (ALF) then the number of stories is 1. \n",
    "2. Number of stairs (steps). If the paragraph mentions \"1+1 ste\" or \"1+1 stairs to enter\", reduce this to 1.\n",
    "3. Number of handrails present. If the paragraph makes no mention of handrails, sometimes abbreviated as \"hr\" or \"hrs\", then this is 0.\n",
    "3. Number of falls in the last six months.\n",
    "4. We will encode the assistive device used, if any:\n",
    "    No assistive device used: 0\n",
    "    Cane: 1\n",
    "    Walker: 2\n",
    "\n",
    "Paragraph:\n",
    "\\\"\\\"\\\"\n",
    "{two_sh_paragraph}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Example response format:\n",
    "1. Number of stories in the house: 2\n",
    "2. Number stairs (steps): 10 (5+2+3) with 0 handrails\n",
    "3. Number falls in last 6 months: 1\n",
    "4. Assistive device used, if any: Walker\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8909c1-13d1-401e-80be-2a5b1b57370c",
   "metadata": {},
   "source": [
    "All information is correct. Let's also provide the first paragraph we had created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0857f75-8139-4a30-8316-fa5b5948fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Number of stories in the house: 2\n",
      "2. Number stairs (steps): 1 with 2 handrails\n",
      "3. Number of falls in last 6 months: 3\n",
      "4. Assistive device used, if any: 2\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Analyze the following paragraph. The paragraph describes the living situation and prior level of function of \n",
    "a patient who is admitted in the hospital.\n",
    "\n",
    "Extract the following information and return it in the format listed below the paragraph.\n",
    "1. Number of stories in the living arrangement that the patient was previously at, or the patient is planning to return.\n",
    "If this is a apartment, independent living facility (ILF), skilled nursing facility (SNF), nursing home (NH), long-term care facility (LTC),\n",
    "or assisted living facility (ALF) then the number of stories is 1. \n",
    "2. Number of stairs (steps). If the paragraph mentions \"1+1 ste\" or \"1+1 stairs to enter\", reduce this to 1.\n",
    "3. Number of handrails present. If the paragraph makes no mention of handrails, sometimes abbreviated as \"hr\" or \"hrs\", then this is 0.\n",
    "3. Number of falls in the last six months.\n",
    "4. We will encode the assistive device used, if any:\n",
    "    No assistive device used: 0\n",
    "    Cane: 1\n",
    "    Walker: 2\n",
    "\n",
    "Paragraph:\n",
    "\\\"\\\"\\\"\n",
    "{two_sh_paragraph}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Example response format:\n",
    "1. Number of stories in the house: 2\n",
    "2. Number stairs (steps): 10 with 0 handrails\n",
    "3. Number falls in last 6 months: 1\n",
    "4. Assistive device used, if any: 2\n",
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [\n",
    "        {\"role\":\"user\",\"content\":prompt}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a4c58-c833-48a7-8067-9c4aa24137de",
   "metadata": {},
   "source": [
    "Again, all of the information is correct. We will now use OpenAI API to analyze the prior level of function and mobility assessment portions of othe document. We will supply the GPT with background information and specific information regarding response formatting in order to seamlessly retrieve our data in a format we can create our final dataframe with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9684e9a7-896b-49ce-9883-9ab30dac9a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "[2, 16, 0, 1, 1]\n",
      "```\n",
      "```python\n",
      "[0, 1, 0, 0, 2]\n",
      "```\n",
      "```python\n",
      "[4, 0, 0, 2, 2]\n",
      "```\n",
      "[4, 0, 0, 0, 2]\n",
      "[3, 0, 0, 1, 0]\n",
      "```python\n",
      "[0, 10, 1, 0, 1]\n",
      "```\n",
      "```python\n",
      "[1, 1, 0, 0, 1]\n",
      "```\n",
      "```python\n",
      "[0, 1, 0, 0, 0]\n",
      "```\n",
      "```python\n",
      "[4, 0, 0, 0, 1]\n",
      "```\n",
      "```python\n",
      "[4, 0, 0, 2, 5]\n",
      "```\n",
      "[2, 0, 4, 4, 3, 0, 1, 0, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "list_pattern = '(\\[.*\\])'\n",
    "\n",
    "for eval_plof in plof:\n",
    "    plof_prompt = f\"\"\"\n",
    "    You are an automated data extractor. Your only goal is to analyze the following paragraph for the data listed and return it in the format\n",
    "    required below. The paragraph describes the living situation and prior level of function of \n",
    "    a patient who is admitted in the hospital.\n",
    "    \n",
    "    Extract the following information and return it in the format listed below the paragraph.\n",
    "    1. Type of location that the patient was living in. If they plan to live in another location, such as an individual who lives in a two story home\n",
    "    but plans to stay in a ranch home, then encode the ranch home. We will encode this as follows:\n",
    "        Ranch home or single story home (ssh): 0\n",
    "        Two or more story home (2sh): 1\n",
    "        Apartment: 2\n",
    "        Independent living facility (ILF): 3\n",
    "        Assisted living facility (ALF): 4\n",
    "        Skilled nursing facility (SNF): 5\n",
    "        Inpatient rehabilitation hospital: 6\n",
    "        Long-term care facility (LTC): 7\n",
    "    2. Number of stairs (steps). If the paragraph mentions \"1+1 ste\" or \"1+1 stairs to enter\", reduce this to 1. Otherwise, \n",
    "    perform the necessary addition.\n",
    "    3. Number of handrails present. If the paragraph makes no mention of handrails, sometimes abbreviated as \"hr\" or \"hrs\", then this is 0.\n",
    "    4. Type of assistive device used. If this is not mentioned, then assume no assistive device. We will encode the assistive device used, if any:\n",
    "        No assistive device used: 0\n",
    "        Cane: 1\n",
    "        Walker: 2\n",
    "    5. Number of falls in the last six months.\n",
    "    \n",
    "    \n",
    "    Paragraph:\n",
    "    \\\"\\\"\\\"\n",
    "    {eval_plof}\n",
    "    \\\"\\\"\\\"\n",
    "    \n",
    "    Response format will be in the form of a python list with only the integers returned. For example: \"[ 1, 3, 2, 0, 3]\" where:\n",
    "        Number of stories in the house is at index 1.\n",
    "        Number stairs (steps) is at index 2.\n",
    "        Number of handrails is at index 3.\n",
    "        Assistive device used is at index 4.\n",
    "        Number of falls in the last 6 months is at index 5.\n",
    "\n",
    "    Do not return an explanation. Only return the python list.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = [\n",
    "            {\"role\":\"user\",\"content\":plof_prompt}\n",
    "        ]\n",
    "    )\n",
    "    gpt_plof_response = response.choices[0].message.content\n",
    "    print(gpt_plof_response)\n",
    "    plof_list = ast.literal_eval(re.search(list_pattern,gpt_plof_response).group())\n",
    "    prior_loc.append(plof_list[0])\n",
    "    ste.append(plof_list[1])\n",
    "    hr.append(plof_list[2])\n",
    "    ad.append(plof_list[3])\n",
    "    num_falls.append(plof_list[4])\n",
    "\n",
    "print(prior_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21261836-144e-4280-9463-b205a2d2af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "[2, 4, 4, 0, 4, 0]\n",
      "```\n",
      "```python\n",
      "[1, 1, 1, 125, 2, 1]\n",
      "```\n",
      "```python\n",
      "[0, 0, 1, 50, 4, 0]\n",
      "```\n",
      "[1, 2, 1, 5, 4, 0]\n",
      "```python\n",
      "[0, 0, 0, 150, 0, 9]\n",
      "```\n",
      "```python\n",
      "[2, 1, 1, 100, 4, 0]\n",
      "```\n",
      "```python\n",
      "[1, 1, 1, 350, 0, 18]\n",
      "```\n",
      "[2, 2, 4, 0, 4, 0]\n",
      "```python\n",
      "[1, 1, 1, 50, 4, 0]\n",
      "```\n",
      "```python\n",
      "[3, 3, 4, 0, 4, 0]\n",
      "```\n",
      "[2, 1, 0, 1, 0, 2, 1, 2, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "# We are using the ast package to convert our returned python literal into a list to be iterated\n",
    "import ast\n",
    "list_pattern = '(\\[.*\\])'\n",
    "\n",
    "for eval_mob in mobility:\n",
    "    mobility_prompt = f\"\"\"\n",
    "    \n",
    "    You are an automated data extractor. Your only goal is to analyze the following paragraph for the data listed and return it in the format\n",
    "    required below. The paragraph describes the mobility assessment performed on a patient following a surgical fusion \n",
    "    that is in an inpatient hospital. \n",
    "    \n",
    "    The purpose of this analysis is to retrieve information regarding the assistance required to perform various mobility, \n",
    "    distance of ambulation, and number of stairs completed during the session. Some portions of information may not be available as they \n",
    "    might not have been performed.\n",
    "    \n",
    "    Assistance ranges from:\n",
    "    SBA: Stand-by-assistance\n",
    "    Min-A: Minimal assistance\n",
    "    Mod-A: Moderate assistance\n",
    "    Max-A: Maximal Assistance\n",
    "    'x#' where # is the number of individuals assisting. For example, minAx1 means minimal assistance of 1.\n",
    "    \n",
    "    Distance is measured in feet.\n",
    "    \n",
    "    Extract the following information and return it in the format listed below the paragraph. \n",
    "    1. Supine to sit (also written as sup < > sit or sup to sit) assistance required\n",
    "    2. Sit to stand (also written as sit < > stand) assistance required\n",
    "    3. Ambulation assistance required\n",
    "    4. Ambulation distance (If Ambulation assistance required is 4, then this value is 0.)\n",
    "    5. Stairs assistance required\n",
    "    6. Stairs completed (If stairs assistance is 4, then this value is 0.)\n",
    "    \n",
    "    Paragraph:\n",
    "    \\\"\\\"\\\"\n",
    "    {eval_mob}\n",
    "    \\\"\\\"\\\"\n",
    "    \n",
    "    Return the assistance variables in the encoded format:\n",
    "    Stand-by-assistance: 0\n",
    "    Minimal assistance of 1: 1\n",
    "    Moderate assistance of 1: 2\n",
    "    Maximal assistance of 1 or more, moderate assistance of 2: 3\n",
    "    Unable to complete, did not complete, or not feasible to complete: 4\n",
    "    \n",
    "    Response format will only be in the form of a python list with only the integers returned. For example: \"[ 1, 3, 2, 100, 3, 6]\"\n",
    "    where:\n",
    "        Supine to sit assistance is index 0.\n",
    "        Sit to stand assistance is index 1.\n",
    "        Ambulation assistance is index 2.\n",
    "        Ambulation distance is index 3.\n",
    "        Stairs assistance is index 4.\n",
    "        Stairs completed is index 5.\n",
    "\n",
    "    Do not return an explanation. Only return the python list.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = [\n",
    "            {\"role\":\"user\",\"content\":mobility_prompt}\n",
    "        ]\n",
    "    )\n",
    "    gpt_mob_response = response.choices[0].message.content\n",
    "    print(gpt_mob_response)\n",
    "    mobility_list = ast.literal_eval(re.search(list_pattern,gpt_mob_response).group())\n",
    "    sup_sit.append(mobility_list[0])\n",
    "    sit_stand.append(mobility_list[1])\n",
    "    amb_assist.append(mobility_list[2])\n",
    "    amb_distance.append(mobility_list[3])\n",
    "    stairs_assist.append(mobility_list[4])\n",
    "    num_stairs.append(mobility_list[5])\n",
    "print(sup_sit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e2359-9ba0-4b1d-8736-1cb4fa0427d8",
   "metadata": {},
   "source": [
    "## Aggregation of the Data into a single Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41ffaefc-4066-4817-822f-eb46858235b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    'age' : age,\n",
    "    'sex' : sex,\n",
    "    'fusion' : fusion,\n",
    "    'provider' : provider,\n",
    "    'brace' : brace,\n",
    "    'pain' : pain,\n",
    "    'prior_loc' : prior_loc,\n",
    "    'ste' : ste,\n",
    "    'hr' : hr,\n",
    "    'ad' : ad,\n",
    "    'num_falls' : num_falls,\n",
    "    'sup_sit' : sup_sit,\n",
    "    'sit_stand' : sit_stand,\n",
    "    'amb_assist' : amb_assist,\n",
    "    'amb_distance' : amb_distance,\n",
    "    'stairs_assist' : stairs_assist,\n",
    "    'num_stairs' : num_stairs\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "## Conversion of integer columns to type Integer\n",
    "for col in columns: \n",
    "    if col not in ('sex', 'fusion', 'provider', 'brace'):\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc43f5e-6bc9-41f0-a2d8-31664d73dfee",
   "metadata": {},
   "source": [
    "We will import the functions used in the **Evaluation Generator** part of this project to categorize pain and predict our label columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac0544cd-621f-4a34-8096-dba69f21efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_predict import guess_los, guess_dc_loc, categorize_pain, calc_rehab\n",
    "\n",
    "df['los'] = (\n",
    "    df.apply(lambda row: guess_los(row['fusion'], row['pain'], row['amb_distance'], row['num_falls']), axis = 1)\n",
    ")\n",
    "df['dc_loc'] = (\n",
    "    df.apply(lambda row: guess_dc_loc(row['prior_loc'], row['fusion'], row['pain'], row['amb_distance'], \\\n",
    "                                                 row['num_falls']), axis=1)\n",
    ")\n",
    "df['pain'] = (\n",
    "    df['pain'].apply(lambda x: categorize_pain(x))\n",
    ")\n",
    "\n",
    "df['need_rehab'] = df['dc_loc'].apply(lambda x: calc_rehab(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b01f31f-6032-4bce-8b1e-d2e7f3632a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>fusion</th>\n",
       "      <th>provider</th>\n",
       "      <th>brace</th>\n",
       "      <th>pain</th>\n",
       "      <th>prior_loc</th>\n",
       "      <th>ste</th>\n",
       "      <th>hr</th>\n",
       "      <th>ad</th>\n",
       "      <th>num_falls</th>\n",
       "      <th>sup_sit</th>\n",
       "      <th>sit_stand</th>\n",
       "      <th>amb_assist</th>\n",
       "      <th>amb_distance</th>\n",
       "      <th>stairs_assist</th>\n",
       "      <th>num_stairs</th>\n",
       "      <th>los</th>\n",
       "      <th>dc_loc</th>\n",
       "      <th>need_rehab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>female</td>\n",
       "      <td>lumbar</td>\n",
       "      <td>Nolan</td>\n",
       "      <td>lso</td>\n",
       "      <td>moderate</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>male</td>\n",
       "      <td>lumbar</td>\n",
       "      <td>Myers</td>\n",
       "      <td>tlso</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>female</td>\n",
       "      <td>lumbar</td>\n",
       "      <td>Myers</td>\n",
       "      <td>lso</td>\n",
       "      <td>mild</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>male</td>\n",
       "      <td>cervical</td>\n",
       "      <td>Myers</td>\n",
       "      <td>aspen</td>\n",
       "      <td>severe</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>female</td>\n",
       "      <td>cervical</td>\n",
       "      <td>Kuzak</td>\n",
       "      <td>aspen</td>\n",
       "      <td>mild</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82</td>\n",
       "      <td>female</td>\n",
       "      <td>cervical</td>\n",
       "      <td>Kuzak</td>\n",
       "      <td>aspen</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65</td>\n",
       "      <td>male</td>\n",
       "      <td>cervical</td>\n",
       "      <td>Myers</td>\n",
       "      <td>aspen</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72</td>\n",
       "      <td>male</td>\n",
       "      <td>cervical</td>\n",
       "      <td>Myers</td>\n",
       "      <td>aspen</td>\n",
       "      <td>severe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78</td>\n",
       "      <td>male</td>\n",
       "      <td>lumbar</td>\n",
       "      <td>Nolan</td>\n",
       "      <td>lso</td>\n",
       "      <td>severe</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75</td>\n",
       "      <td>male</td>\n",
       "      <td>lumbar</td>\n",
       "      <td>Nolan</td>\n",
       "      <td>tlso</td>\n",
       "      <td>severe</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    fusion provider  brace      pain  prior_loc  ste  hr  ad  \\\n",
       "0   68  female    lumbar    Nolan    lso  moderate          2   16   0   1   \n",
       "1   71    male    lumbar    Myers   tlso  moderate          0    1   0   0   \n",
       "2   70  female    lumbar    Myers    lso      mild          4    0   0   2   \n",
       "3   75    male  cervical    Myers  aspen    severe          4    0   0   0   \n",
       "4   70  female  cervical    Kuzak  aspen      mild          3    0   0   1   \n",
       "5   82  female  cervical    Kuzak  aspen  moderate          0   10   1   0   \n",
       "6   65    male  cervical    Myers  aspen  moderate          1    1   0   0   \n",
       "7   72    male  cervical    Myers  aspen    severe          0    1   0   0   \n",
       "8   78    male    lumbar    Nolan    lso    severe          4    0   0   0   \n",
       "9   75    male    lumbar    Nolan   tlso    severe          4    0   0   2   \n",
       "\n",
       "   num_falls  sup_sit  sit_stand  amb_assist  amb_distance  stairs_assist  \\\n",
       "0          1        2          4           4             0              4   \n",
       "1          2        1          1           1           125              2   \n",
       "2          2        0          0           1            50              4   \n",
       "3          2        1          2           1             5              4   \n",
       "4          0        0          0           0           150              0   \n",
       "5          1        2          1           1           100              4   \n",
       "6          1        1          1           1           350              0   \n",
       "7          0        2          2           4             0              4   \n",
       "8          1        1          1           1            50              4   \n",
       "9          5        3          3           4             0              4   \n",
       "\n",
       "   num_stairs   los  dc_loc  need_rehab  \n",
       "0           0   9.7       6           1  \n",
       "1           1   4.4       0           0  \n",
       "2           0  10.1       6           1  \n",
       "3           0   9.1       6           1  \n",
       "4           9   1.6       3           0  \n",
       "5           0   1.7       0           0  \n",
       "6          18   2.2       1           0  \n",
       "7           0   8.3       6           1  \n",
       "8           0   5.8       4           0  \n",
       "9           0  10.0       6           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86dec5b-f03c-4c2b-a6da-91afbc7b08e4",
   "metadata": {},
   "source": [
    "### Final Statements\n",
    "\n",
    "In a live environment, there are likely changes to be made to this setup. For example, it'd be better to pull check providers against a list of providers in the hospital database. It may also not be entirely feasible to use this form of GPT as OpenAI has a clause that they may choose to keep your prompts for up to 30 days which does contain PHI in this case. As I am very young in the field, there are likely other methods to explore of which I am currently unaware to clean the raw data which may be more precise. There is also more data to be analyzed, such as whether the patient contracted an infection following the procedure which could have significant effects on length-of-stay and need for rehabilitation. Lastly, live environments will come with actual label data which would be essential to create real insights from this analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
